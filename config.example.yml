# Talk2Metadata Configuration Example
# Copy this file to config.yml and customize as needed

# Data directories
data:
  raw_dir: "./data/raw"
  processed_dir: "./data/processed"
  indexes_dir: "./data/indexes"
  metadata_dir: "./data/metadata"

# Schema detection settings
schema:
  fk_detection:
    use_heuristics: true
    inclusion_tolerance: 0.1  # Allow 10% mismatch in FK relationships
    min_coverage: 0.9          # Require 90% coverage for FK inference

# Embedding configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"  # Fast and accurate
  # Alternative models:
  # - "sentence-transformers/all-mpnet-base-v2"  # Higher quality, slower
  # - "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"  # Optimized for QA
  device: null  # null for auto-detect, or 'cpu', 'cuda:0', etc.
  batch_size: 32
  normalize: true

# Retrieval settings
retrieval:
  top_k: 5
  similarity_metric: "cosine"
  per_table_top_k: 5  # For record_embedding mode: results per table before voting

  # Future features
  use_reranking: false  # Requires cross-encoder (optional)

# Mode configuration
# Each mode has its own indexer and retriever settings
modes:
  # Mode: record_embedding
  record_embedding:
    indexer:
      model_name: "sentence-transformers/all-MiniLM-L6-v2"  # Fast and accurate
      # Alternative models:
      # - "sentence-transformers/all-mpnet-base-v2"  # Higher quality, slower
      # - "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"  # Optimized for QA
      device: null  # null for auto-detect, or 'cpu', 'cuda:0', etc.
      batch_size: 32
      normalize: true
    retriever:
      top_k: 5
      similarity_metric: "cosine"
      per_table_top_k: 5  # Results per table before voting
      use_reranking: false  # Requires cross-encoder (optional)

  # Future modes can be added here:
  # future_mode_2:
  #   indexer:
  #     ...
  #   retriever:
  #     ...

  # Global mode settings
  active: "record_embedding"  # Active mode to use for indexing and retrieval
  compare:  # Comparison mode settings
    enabled: false  # Enable comparison mode (runs all modes and compares)
    modes: []  # List of modes to compare (empty = all enabled modes)
    # Example: ["record_embedding", "future_mode_2"]

# Ingest configuration (optional, can be overridden by CLI arguments)
ingest:
  target_table: null  # Target table name (e.g., "orders")
  data_type: null     # Source type: "csv", "database", or "db"
  source_path: null  # Path to CSV directory or database connection string

# Agent configuration (optional, future feature)
agent:
  enabled: false
  provider: "openai"  # openai, anthropic, etc.
  model: "gpt-4o-mini"
  temperature: 0.0
